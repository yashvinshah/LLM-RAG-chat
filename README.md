The project consists of web scrapping data off the wikipedia website.
The LLM agent is then trained on the web scrapped data using retriever augmentation generation (RAG).
A user interface is created using streamlit to provide a chat interface to the users for answering any query based on the scrapped website data.

Provided below is a snippet of the user interface-

![Screenshot 2024-11-23 182107](https://github.com/user-attachments/assets/b38b0c13-3ab5-46d6-a330-38f0e660e25c)

![Screenshot 2024-11-23 182331](https://github.com/user-attachments/assets/35919f31-9c9c-4e5d-9cf0-7d283f41d2e3)

