The project consists of web scrapping data off the wikipedia website.
The LLM agent is then trained on the web scrapped data using retriever augmentation generation (RAG).
A user interface is created using streamlit to provide a chat interface to the users for answering any query based on the scrapped website data.
